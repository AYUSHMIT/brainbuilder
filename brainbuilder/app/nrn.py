'''
          Copyright Adrien Devresse - 2016
 Distributed under the Boost Software License, Version 1.0.
    (See accompanying file LICENSE_1_0.txt or copy at
          http://www.boost.org/LICENSE_1_0.txt)
'''
# pylint: skip-file

import sys
import argparse
import os
import time

#import mpi4py
import h5py


def progress_print(pstr):
    if os.sys.stdout.isatty():
        sys.stdout.write("\r" + pstr)
    else:
        sys.stdout.write(pstr + "\n")
    sys.stdout.flush()

def progress_finalize():
    if os.sys.stdout.isatty():
        sys.stdout.write("\n")
    sys.stdout.flush()


def check_nrndir(nrn_dir):
    if os.path.isdir(nrn_dir) == False:
        raise ValueError("%s is not a valid directory"%(nrn_dir))

def check_individual_file(nrn_file):
    first_file = "%s.0"%(nrn_file)
    if not os.path.exists(first_file):
        print((">WARNING %s ... does not exist ... SKIP"%(first_file)))
        return False
    if os.path.exists(nrn_file):
        print((">WARNING %s ... already exist ... SKIP"%(nrn_file)))
        return False
    return True

def list_nrnfiles(nrn_dir):
    name_files = ["nrn_positions.h5", "nrn_positions_efferent.h5",
                  "nrn.h5", "nrn_summary.h5", "nrn_extra.h5", "nrn_efferent.h5"]

    list_files = [''.join([nrn_dir, os.sep, f]) for f in name_files]
    return filter(check_individual_file, list_files)

def get_nrnfiles(nrn_dir, only):
    if only != "":
        return [''.join([nrn_dir, os.sep, only])]
    return list_nrnfiles(nrn_dir)

def count_subfiles(filename):
    count = 1
    while os.path.exists("%s.%d"%(filename, count)):
        count += 1
    return count

def get_all_dataset(filename, file_number, dset):
    n_filename = "%s.%d"%(filename, file_number)
    f = h5py.File(n_filename, "r")
    all_keys = f.keys();
    dset[file_number] = filter(lambda key: key[0] == 'a', all_keys)
    f.close()
    return len(all_keys)

def finalize_metadata(fdesc, total_files):
    fdesc["/info"] = 0
    attrs = fdesc["/info"].attrs
    attrs.create("numberOfFiles", total_files)
    attrs.create("version", 5)

def create_merged_file(filename, link=False):
    print(">")
    print(">> start merge for %s"%filename)
    total_files = count_subfiles(filename)
    print(">> %d files to merge"%(total_files))
    dset = {}
    n = 0
    t1 = time.time()
    progress_print(">>")
    for i in xrange(0, total_files):
        n += get_all_dataset(filename, i, dset)
        progress_print(">> got all keys for file %s.%d"%(filename, i))
    progress_finalize()
    print(">> complete listing done in %fs"%(time.time() - t1))
    print(">> total of %d datasets to merge"%(n))
    t1 = time.time()
    progress_print(">>")
    with h5py.File(filename, 'w') as merged:
        for i in xrange(0, total_files):
            chunk_filename = "%s.%d" % (filename, i)
            if link:
                progress_print(">> create external references file %s" % chunk_filename)
                for k in dset[i]:
                    d_name = "/%s"%(k)
                    merged[d_name] = h5py.ExternalLink(chunk_filename, d_name)
            else:
                progress_print(">> copy over data from %s" % chunk_filename)
                with h5py.File(chunk_filename, 'r') as chunk:
                    for k in dset[i]:
                        d_name = "/%s"%(k)
                        merged[d_name] = chunk[d_name][:]
        finalize_metadata(merged, (total_files if link else 1))
    progress_finalize()
    print(">> complete merging done in %fs"%(time.time() - t1))


def merge(nrn_dir, only, link):
    """
    Merge utility tool for nrn.h5 Blue Brain synapse file format.

    This tool creates a single file presenting the content of
    a group of nrn_*.h5.N generated by the Functionalizer
    """
    check_nrndir(nrn_dir)
    for filename in get_nrnfiles(nrn_dir, only):
        create_merged_file(filename, link=link)
