'''
          Copyright Adrien Devresse - 2016
 Distributed under the Boost Software License, Version 1.0.
    (See accompanying file LICENSE_1_0.txt or copy at
          http://www.boost.org/LICENSE_1_0.txt)
'''
# pylint: disable=missing-docstring

import sys
import os
import time

from contextlib import contextmanager

#import mpi4py
import click
import h5py
import numpy as np

from tqdm import tqdm


@click.group()
def app():
    """ Tools for working with NRN files """


def progress_print(pstr):
    if os.sys.stdout.isatty():
        sys.stdout.write("\r" + pstr)
    else:
        sys.stdout.write(pstr + "\n")
    sys.stdout.flush()

def progress_finalize():
    if os.sys.stdout.isatty():
        sys.stdout.write("\n")
    sys.stdout.flush()

def check_individual_file(nrn_file):
    first_file = "%s.0"%(nrn_file)
    if not os.path.exists(first_file):
        print((">WARNING %s ... does not exist ... SKIP"%(first_file)))
        return False
    if os.path.exists(nrn_file):
        print((">WARNING %s ... already exist ... SKIP"%(nrn_file)))
        return False
    return True

def list_nrnfiles(nrn_dir):
    name_files = ["nrn_positions.h5", "nrn_positions_efferent.h5",
                  "nrn.h5", "nrn_summary.h5", "nrn_extra.h5", "nrn_efferent.h5"]

    list_files = [''.join([nrn_dir, os.sep, f]) for f in name_files]
    return filter(check_individual_file, list_files)

def get_nrnfiles(nrn_dir, only):
    if only != "":
        return [''.join([nrn_dir, os.sep, only])]
    return list_nrnfiles(nrn_dir)

def count_subfiles(filename):
    count = 1
    while os.path.exists("%s.%d"%(filename, count)):
        count += 1
    return count

def get_all_dataset(filename, file_number, dset):
    n_filename = "%s.%d"%(filename, file_number)
    with h5py.File(n_filename, 'r') as f:
        all_keys = f.keys()
        dset[file_number] = list(filter(lambda key: key[0] == 'a', all_keys))
        return len(all_keys)

def finalize_metadata(fdesc, total_files):
    fdesc["/info"] = 0
    attrs = fdesc["/info"].attrs
    attrs.create("numberOfFiles", total_files)
    attrs.create("version", 5)

def create_merged_file(filename, link=False):
    print(">")
    print(">> start merge for %s"%filename)
    total_files = count_subfiles(filename)
    print(">> %d files to merge"%(total_files))
    dset = {}
    n = 0
    t1 = time.time()
    progress_print(">>")
    for i in range(0, total_files):
        n += get_all_dataset(filename, i, dset)
        progress_print(">> got all keys for file %s.%d"%(filename, i))
    progress_finalize()
    print(">> complete listing done in %fs"%(time.time() - t1))
    print(">> total of %d datasets to merge"%(n))
    t1 = time.time()
    progress_print(">>")
    with h5py.File(filename, 'w') as merged:
        for i in range(0, total_files):
            chunk_filename = "%s.%d" % (filename, i)
            if link:
                progress_print(">> create external references file %s" % chunk_filename)
                for k in dset[i]:
                    d_name = "/%s"%(k)
                    merged[d_name] = h5py.ExternalLink(chunk_filename, d_name)
            else:
                progress_print(">> copy over data from %s" % chunk_filename)
                with h5py.File(chunk_filename, 'r') as chunk:
                    for k in dset[i]:
                        d_name = "/%s"%(k)
                        merged[d_name] = chunk[d_name][:]
        finalize_metadata(merged, (total_files if link else 1))
    progress_finalize()
    print(">> complete merging done in %fs"%(time.time() - t1))


@contextmanager
def cd(dirpath):
    old_dirpath = os.getcwd()
    new_dirpath = os.path.abspath(dirpath)
    os.chdir(new_dirpath)
    try:
        yield new_dirpath
    finally:
        os.chdir(old_dirpath)


@app.command()
@click.argument("nrn_dir")
@click.option(
    "--only", help="merge only the specified file (e.g --only=nrn_positions.h5)", default=""
)
@click.option(
    "--link", is_flag=True, help="make symbolic links instead of copying datasets"
)
def merge(nrn_dir, only, link):
    """
    Merge utility tool for nrn.h5 Blue Brain synapse file format.

    This tool creates a single file presenting the content of
    a group of nrn_*.h5.N generated by the Functionalizer
    """
    with cd(nrn_dir):
        # chdir to NRN folder to make NRN links relative
        for filename in get_nrnfiles('.', only):
            create_merged_file(filename, link=link)


@app.command()
@click.argument("syn2")
@click.option("-o", "--output", help="Path to output NRN folder", required=True)
def from_syn2(syn2, output):
    """Convert SYN2 file to partial nrn.h5"""
    with h5py.File(syn2, 'r') as h5f:
        assert len(h5f['synapses']) == 1
        src = next(iter(h5f['synapses'].values()))
        prop = src['properties']
        index1 = src['indexes/connected_neurons_post/neuron_id_to_range']
        index2 = src['indexes/connected_neurons_post/range_to_synapse_id']
        with h5py.File(os.path.join(output, 'nrn.h5'), 'w') as dst:
            dst['info'] = []
            dst['info'].attrs['version'] = [5]
            for gid, rng1 in tqdm(enumerate(index1), total=len(index1)):
                r1_0, r1_1 = rng1.astype(int)
                if r1_0 >= r1_1:
                    continue
                for r1 in range(r1_0, r1_1 - 1):
                    assert index2[r1][1] == index2[r1 + 1][0]  # assert postsynaptic sorting
                rng2 = range(index2[r1_0][0], index2[r1_1 - 1][1])
                NA = np.full(len(rng2), -1)
                dst['a%d' % (1 + gid)] = np.stack([
                    1 + prop['connected_neurons_pre'][rng2],  # 0
                    prop['delay'][rng2],                      # 1
                    prop['morpho_section_id_post'][rng2],     # 2
                    prop['morpho_segment_id_post'][rng2],     # 3
                    prop['morpho_offset_segment_post'][rng2], # 4
                    prop['morpho_section_id_pre'][rng2],      # 5
                    prop['morpho_segment_id_pre'][rng2],      # 6
                    prop['morpho_offset_segment_pre'][rng2],  # 7
                    prop['conductance'][rng2],                # 8
                    prop['u_syn'][rng2],                      # 9
                    prop['depression_time'][rng2],            # 10
                    prop['facilitation_time'][rng2],          # 11
                    prop['decay_time'][rng2],                 # 12
                    prop['syn_type_id'][rng2],                # 13
                    NA, # morphology type of the pre neuron   # 14
                    NA, # dendrite branch order               # 15
                    NA, # axon branch order                   # 16
                    prop['n_rrp_vesicles'][rng2],             # 17
                    NA, # postsynaptic branch type            # 18
            ]).transpose().astype(np.float32)
